{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Install Pandas (For CI Success) - Already installed Locally\n",
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Install Matplotlib (For CI Success) - Already installed Locally\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Install SeaBorn (For CI Success) - Already installed Locally\n",
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Install NLTK (For CI Success) - Already installed Locally\n",
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Install sklearn (For CI Success) - Already installed Locally\n",
    "%pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install seaborn (For CI Success) - Already installed Locally\n",
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "import re\n",
    "import sklearn\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read googleplaystore_user_reviews.csv \n",
    "df = pd.read_csv('../googleplaystore_user_reviews.csv', encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are only interested in the Translated_Review and Sentiment Column\n",
    "#df = pd.concat([df.Translated_Review,df.Sentiment], axis = 1)\n",
    "df.dropna(axis = 0, inplace = True) #drop nan\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing our Sentiment Data\n",
    "sns.countplot(df.Sentiment)\n",
    "plt.title('Count of Sentiments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scatter Plotting\n",
    "plt.figure(figsize=(10,10))\n",
    "j = sns.scatterplot(df.Sentiment_Polarity,df.Sentiment_Subjectivity,hue=df.Sentiment, edgecolor='pink',palette=\"plasma_r\")\n",
    "plt.xlabel('Sentiment Polarity', fontsize=20)\n",
    "plt.ylabel('Sentiment Subjectivity', fontsize=20)\n",
    "plt.title(\"Sentiment Analysis\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Import stopwords list to remove them from the Reviews\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "#Now we Pre Process all the customer reviews\n",
    "processed_list = []\n",
    "for i in df.Translated_Review:\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", i)\n",
    "    text = text.lower()\n",
    "    text = nltk.word_tokenize(text)\n",
    "    lemma = nltk.WordNetLemmatizer()\n",
    "    text = [lemma.lemmatize(word) for word in text]\n",
    "    text = \" \".join(text)\n",
    "    processed_list.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Import CountVectorizer from Sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#Now we will create a bag of words using the CountVectorizer of sklearn\n",
    "\n",
    "max_features=1000 #We consider the top 1000 features ordered by term frequency across the corpus\n",
    "count_vectorizer=CountVectorizer(max_features=max_features)\n",
    "sparce_matrix=count_vectorizer.fit_transform(processed_list).toarray()\n",
    "bag_of_words=count_vectorizer.get_feature_names()\n",
    "\n",
    "#print(\"Most used 50 words: \",bag_of_words[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Classification Using Different Classification Algorithms\n",
    "y = df.iloc[:,2].values\n",
    "x = sparce_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now first we have to split our data into two,\n",
    "#training data set and testing data set for that\n",
    "#we make use of train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#First Classifier: NAIVE BAYES CLASSIFIER\n",
    "#import guassian naive bayes classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "naive_bayes = GaussianNB()\n",
    "naive_bayes.fit(xtrain, ytrain)\n",
    "print('Accuracy:', naive_bayes.score(xtest, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix for naive bayes classifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_predicted=naive_bayes.predict(xtest)\n",
    "y_true = ytest\n",
    "names=[\"Positive\",\"Negative\",\"Neutral\"]\n",
    "cm=confusion_matrix(y_true,y_predicted)\n",
    "f,ax=plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(cm,annot=True,linewidth=.5,linecolor=\"r\",fmt=\".0f\",ax=ax)\n",
    "plt.xlabel(\"y_predicted\")\n",
    "plt.ylabel(\"y_true\")\n",
    "ax.set_xticklabels(names)\n",
    "ax.set_yticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second Classifier: RANDOM FOREST CLASSIFIER\n",
    "#import random forest classfier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators = 10, random_state = 42)\n",
    "random_forest.fit(xtrain, ytrain)\n",
    "print(\"Accuracy: \", random_forest.score(xtest, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix for Random Forest Classifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "y_predicted=random_forest.predict(xtest)\n",
    "y_true = ytest\n",
    "names=[\"Positive\",\"Negative\",\"Neutral\"]\n",
    "cm=confusion_matrix(y_true,y_predicted)\n",
    "f,ax=plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(cm,annot=True,linewidth=.5,linecolor=\"r\",fmt=\".0f\",ax=ax)\n",
    "plt.xlabel(\"y_predicted\")\n",
    "plt.ylabel(\"y_true\")\n",
    "ax.set_xticklabels(names)\n",
    "ax.set_yticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Thir Classifier: Logisitic Regression\n",
    "#import logistic regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_regression = LogisticRegression(random_state= 42)\n",
    "logistic_regression.fit(xtrain, ytrain)\n",
    "print(\"Accuracy: \", logistic_regression.score(xtest, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix for logistic regression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_predicted=logistic_regression.predict(xtest)\n",
    "y_true = ytest\n",
    "names=[\"Positive\",\"Negative\",\"Neutral\"]\n",
    "cm=confusion_matrix(y_true,y_predicted)\n",
    "f,ax=plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(cm,annot=True,linewidth=.5,linecolor=\"r\",fmt=\".0f\",ax=ax)\n",
    "plt.xlabel(\"y_predicted\")\n",
    "plt.ylabel(\"y_true\")\n",
    "ax.set_xticklabels(names)\n",
    "ax.set_yticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = x\n",
    "data_y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using K Fold Cross Validation Technique\n",
    "# import KFold from sklearn\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state = 42)"
   ]
  },
  {
   "source": [
    "#using 10 fold cross validation technique to evaluate the model\n",
    "#NAIVE BAYES CLASSIFIER\n",
    "#scores_naive_bayes will contain scores of all 10 folds\n",
    "scores_naive_bayes = []\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "naive_bayes = GaussianNB()\n",
    "\n",
    "for train_index, test_index in k_fold.split(data_x):\n",
    "    xtrain, xtest, ytrain, ytest = data_x[train_index], data_x[test_index], data_y[train_index], data_y[test_index]\n",
    "    naive_bayes.fit(xtrain, ytrain)\n",
    "    scores_naive_bayes.append(naive_bayes.score(xtest, ytest))\n",
    "\n",
    "print(\"Accuracy: \", np.mean(scores_naive_bayes))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM FOREST CLASSIFIER\n",
    "#scores_naive_bayes will contain scores of all 10 folds\n",
    "scores_random_forest = []\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random_forest = RandomForestClassifier(n_estimators = 10, random_state = 42)\n",
    "\n",
    "for train_index, test_index in k_fold.split(data_x):\n",
    "    xtrain, xtest, ytrain, ytest = data_x[train_index], data_x[test_index], data_y[train_index], data_y[test_index]\n",
    "    random_forest.fit(xtrain, ytrain)\n",
    "    scores_random_forest.append(random_forest.score(xtest, ytest))\n",
    "\n",
    "print(\"Accuracy: \", np.mean(scores_random_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOGISTIC REGRESSION\n",
    "#scores_logistic_regression will contain scores of all 10 folds\n",
    "scores_logistic_regression = []\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_regression = LogisticRegression()\n",
    "\n",
    "for train_index, test_index in k_fold.split(data_x):\n",
    "    xtrain, xtest, ytrain, ytest = data_x[train_index], data_x[test_index], data_y[train_index], data_y[test_index]\n",
    "    logistic_regression.fit(xtrain, ytrain)\n",
    "    scores_logistic_regression.append(logistic_regression.score(xtest, ytest))\n",
    "\n",
    "print(\"Accuracy: \", np.mean(scores_logistic_regression))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.8.6 64-bit",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "da34ebd6defbee218801f1d0737e707c0805e0191a59d87bc846853b6311ffcb"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}